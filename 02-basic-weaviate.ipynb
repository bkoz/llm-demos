{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de20cfe-47b7-484b-9d19-48dfed1d9c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:OLLAMA_API_ENDPOINT = http://ollama.ollama\n",
      "INFO:root:Connecting to Weaviate embedded instance\n",
      "INFO:weaviate-client:Started /opt/app-root/src/.cache/weaviate-embedded: process ID 1574\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":36987},\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"address\":\"10.130.2.38:36988\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"address\":\"10.130.2.38:36987\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"database has been successfully loaded\",\"n\":0,\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"action\":\"raft\",\"index\":59,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:10.130.2.38:36909}]]\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":62,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":62,\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-10-04T19:41:21Z\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":16,\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":16,\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"index\":\"Question\",\"level\":\"info\",\"msg\":\"restore local index\",\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-04T19:41:22Z\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard question_QMPLTZ94ZqFY in 4.912981ms\",\"time\":\"2024-10-04T19:41:22Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-04T19:41:22Z\",\"took\":5583675}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "{\"address\":\"10.130.2.38:36987\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/openid-configuration \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/ready \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/ready \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Found 1 Weaviate nodes.\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Node(git_hash='\\'\"$GITHASH\"\\'', name='Embedded_at_8079', shards=None, stats=None, status='HEALTHY', version='1.25.6')\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:root:client.get_meta(): {'hostname': 'http://127.0.0.1:8079', 'modules': {'generative-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion', 'name': 'Generative Search - Ollama'}, 'text2vec-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings', 'name': 'Ollama Module'}}, 'version': '1.25.6'}\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/schema \"HTTP/1.1 200 OK\"\n",
      "{\"action\":\"load_all_shards\",\"level\":\"error\",\"msg\":\"failed to load all shards: context canceled\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "INFO:httpx:HTTP Request: DELETE http://localhost:8079/v1/schema/Question \"HTTP/1.1 200 OK\"\n",
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /opt/app-root/src/.local/share/weaviate/question/CgiUlwR70aoQ/proplengths does not exist, creating new tracker\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-10-04T19:41:23Z\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard question_CgiUlwR70aoQ in 1.14633ms\",\"time\":\"2024-10-04T19:41:23Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-10-04T19:41:23Z\",\"took\":104116}\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8079/v1/schema \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Importing 1000 Questions...\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:4efec3a8-3feb-436d-9222-5d5d2f25e15d Type:INIT Version:1.25.6 NumObjects:0 OS:linux Arch:amd64 UsedModules:[generative-ollama text2vec-ollama]}\",\"time\":\"2024-10-04T19:41:24Z\"}\n",
      "INFO:root:Finished Importing Questions\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/schema/Question \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Collection: <weaviate.Collection config={\n",
      "  \"name\": \"Question\",\n",
      "  \"description\": null,\n",
      "  \"generative_config\": {\n",
      "    \"generative\": \"generative-ollama\",\n",
      "    \"model\": {\n",
      "      \"apiEndpoint\": \"http://ollama.ollama\",\n",
      "      \"model\": \"llama3.2\"\n",
      "    }\n",
      "  },\n",
      "  \"inverted_index_config\": {\n",
      "    \"bm25\": {\n",
      "      \"b\": 0.75,\n",
      "      \"k1\": 1.2\n",
      "    },\n",
      "    \"cleanup_interval_seconds\": 60,\n",
      "    \"index_null_state\": false,\n",
      "    \"index_property_length\": false,\n",
      "    \"index_timestamps\": false,\n",
      "    \"stopwords\": {\n",
      "      \"preset\": \"en\",\n",
      "      \"additions\": null,\n",
      "      \"removals\": null\n",
      "    }\n",
      "  },\n",
      "  \"multi_tenancy_config\": {\n",
      "    \"enabled\": false,\n",
      "    \"auto_tenant_creation\": false,\n",
      "    \"auto_tenant_activation\": false\n",
      "  },\n",
      "  \"properties\": [\n",
      "    {\n",
      "      \"name\": \"category\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"question\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"answer\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"air_date\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"value\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"number\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": false,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": null,\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"round\",\n",
      "      \"description\": \"This property was generated by Weaviate's auto-schema feature on Fri Oct  4 19:41:23 2024\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": false\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-ollama\"\n",
      "    }\n",
      "  ],\n",
      "  \"references\": [],\n",
      "  \"replication_config\": {\n",
      "    \"factor\": 1,\n",
      "    \"async_enabled\": false\n",
      "  },\n",
      "  \"reranker_config\": null,\n",
      "  \"sharding_config\": {\n",
      "    \"virtual_per_physical\": 128,\n",
      "    \"desired_count\": 1,\n",
      "    \"actual_count\": 1,\n",
      "    \"desired_virtual_count\": 128,\n",
      "    \"actual_virtual_count\": 128,\n",
      "    \"key\": \"_id\",\n",
      "    \"strategy\": \"hash\",\n",
      "    \"function\": \"murmur3\"\n",
      "  },\n",
      "  \"vector_index_config\": {\n",
      "    \"quantizer\": null,\n",
      "    \"cleanup_interval_seconds\": 300,\n",
      "    \"distance_metric\": \"cosine\",\n",
      "    \"dynamic_ef_min\": 100,\n",
      "    \"dynamic_ef_max\": 500,\n",
      "    \"dynamic_ef_factor\": 8,\n",
      "    \"ef\": -1,\n",
      "    \"ef_construction\": 128,\n",
      "    \"flat_search_cutoff\": 40000,\n",
      "    \"max_connections\": 64,\n",
      "    \"skip\": false,\n",
      "    \"vector_cache_max_objects\": 1000000000000\n",
      "  },\n",
      "  \"vector_index_type\": \"hnsw\",\n",
      "  \"vectorizer_config\": {\n",
      "    \"vectorizer\": \"text2vec-ollama\",\n",
      "    \"model\": {\n",
      "      \"apiEndpoint\": \"http://ollama.ollama\",\n",
      "      \"model\": \"all-minilm\"\n",
      "    },\n",
      "    \"vectorize_collection_name\": true\n",
      "  },\n",
      "  \"vectorizer\": \"text2vec-ollama\",\n",
      "  \"vector_config\": null\n",
      "}>\n",
      "/opt/app-root/lib64/python3.9/site-packages/gradio/routes.py:1215: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/fastapi/applications.py:4495: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  return self.router.on_event(event_type)\n",
      "INFO:httpx:HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "/opt/app-root/lib64/python3.9/site-packages/gradio/route_utils.py:871: DeprecationWarning: The loop argument is deprecated since Python 3.8, and scheduled for removal in Python 3.10.\n",
      "  app.stop_event = asyncio.Event(loop=loop)\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8082/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://localhost:8082/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://82019b2bfb448cc461.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://82019b2bfb448cc461.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://82019b2bfb448cc461.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from huggingface_hub import InferenceClient\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import weaviate\n",
    "\n",
    "ollama_api_endpoint = os.getenv(\"OLLAMA_HOST\", \"http://ollama.ollama\")\n",
    "ollama_vectorizer_model = model = \"all-minilm\"\n",
    "ollama_generative_model=\"llama3.2\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(f'OLLAMA_API_ENDPOINT = {ollama_api_endpoint}')\n",
    "\n",
    "def connect_weaviate_embedded():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logging.info('Connecting to Weaviate embedded instance')\n",
    "    client = weaviate.connect_to_embedded(\n",
    "        environment_variables={\"ENABLE_MODULES\": \"text2vec-ollama,generative-ollama\"},\n",
    "        version=\"1.25.6\"\n",
    "    )\n",
    "    return client\n",
    "\n",
    "client = connect_weaviate_embedded()\n",
    "\n",
    "if client.is_ready():\n",
    "    logging.info('')\n",
    "    logging.info(f'Found {len(client.cluster.nodes())} Weaviate nodes.')\n",
    "    logging.info('')\n",
    "    for node in client.cluster.nodes():\n",
    "        logging.info(node)\n",
    "        logging.info('')\n",
    "    logging.info(f'client.get_meta(): {client.get_meta()}')\n",
    "else:\n",
    "    logging.error(\"Client is not ready\")\n",
    "\n",
    "client.collections.delete_all()\n",
    "\n",
    "# lets create the collection, specifing our base url accordingling\n",
    "questions = client.collections.create(\n",
    "    \"Question\",\n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n",
    "        api_endpoint=ollama_api_endpoint,\n",
    "        model=ollama_vectorizer_model\n",
    "    ),\n",
    "    generative_config=wvc.config.Configure.Generative.ollama(\n",
    "        api_endpoint=ollama_api_endpoint,\n",
    "        model=ollama_generative_model\n",
    "    )\n",
    ")\n",
    "resp = requests.get('https://raw.githubusercontent.com/databyjp/wv_demo_uploader/main/weaviate_datasets/data/jeopardy_1k.json')\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "question_objs = list()\n",
    "for i, d in enumerate(data):\n",
    "    question_objs.append({\n",
    "        \"answer\": d[\"Answer\"],\n",
    "        \"question\": d[\"Question\"],\n",
    "        \"category\": d[\"Category\"],\n",
    "        \"air_date\": d[\"Air Date\"],\n",
    "        \"round\": d[\"Round\"],\n",
    "        \"value\": d[\"Value\"]\n",
    "})\n",
    "\n",
    "logging.info('Importing 1000 Questions...')\n",
    "questions = client.collections.get(\"Question\")\n",
    "questions.data.insert_many(question_objs)\n",
    "logging.info('Finished Importing Questions')\n",
    "\n",
    "logging.info(f'Collection: {questions}')\n",
    "\n",
    "def respond(query='computers', task='Summarize', limit=1) -> str:\n",
    "    print(f'\\nPerforming generative search, query = {query}, limit = {limit}.')\n",
    "    print(f'Prompt: {task}')\n",
    "    print(f'limit = {limit}')\n",
    "    response = questions.generate.near_text(\n",
    "        query=query,\n",
    "        limit=limit,\n",
    "        grouped_task=task\n",
    "    )\n",
    "    return response.generated\n",
    "\n",
    "with gr.Blocks(title=\"Search the Jeopardy Vector Database. (powered by Weaviate and Ollama)\") as demo:\n",
    "            gr.Markdown(\"\"\"# Search and summarize the Jeopardy Vector Database. (Powered by Weaviate and Ollama)\"\"\")\n",
    "            semantic_examples = [\n",
    "                [\"Nature\"],\n",
    "                [\"Music\"],\n",
    "                [\"Wine\"],\n",
    "                [\"Consumer Products\"],\n",
    "                [\"Sports\"],\n",
    "                [\"Fishing\"],\n",
    "                [\"Food\"],\n",
    "                [\"Weather\"]\n",
    "            ]\n",
    "            semantic_input_text = gr.Textbox(label=\"Enter a search concept or choose an example below:\", \n",
    "                value=semantic_examples[0][0])\n",
    "            gr.Examples(semantic_examples, inputs=semantic_input_text, label=\"Example search concepts:\")\n",
    "            vdb_button = gr.Button(value=\"Search and Summarize the Jeopardy Vector Database.\")\n",
    "            vdb_button.click(fn=respond, inputs=[semantic_input_text], outputs=gr.Textbox(label=\"Search Results\"))\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name='0.0.0.0', server_port=8082, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e618d4a-dd54-4654-9323-ef0fade03351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
