{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdce3d0-3e19-4018-8e20-35d45f34975e",
   "metadata": {},
   "source": [
    "### FinRAG Demo with Gradio, Weaviate and Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376adfc-a3e3-4926-a663-defee5e8c5ec",
   "metadata": {},
   "source": [
    "#### This notebook expects the Ollama server to be backed by GPU with 16GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742381c-7de1-4e78-a05b-0933fbf945c7",
   "metadata": {},
   "source": [
    "#### This is a lite version that uses Weaviate's embedded instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33e061a-3c67-4719-a9ec-88dcd3f3d5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pip gradio weaviate_client wget ijson -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f2d3fd-781a-472b-b29a-c99bc3df5b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:OLLAMA_API_ENDPOINT = http://ollama.ollama\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from huggingface_hub import InferenceClient\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import ijson\n",
    "import weaviate\n",
    "\n",
    "ollama_api_endpoint = os.getenv(\"OLLAMA_HOST\", \"http://ollama.ollama\")\n",
    "ollama_vectorizer_model = model = \"all-minilm\"\n",
    "ollama_generative_model=\"granite3-dense:8b\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(f'OLLAMA_API_ENDPOINT = {ollama_api_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2814fc4-5762-4665-9343-a5f4ff637e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def connect_weaviate_embedded():\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    logging.info('Connecting to Weaviate embedded instance')\n",
    "    client = weaviate.connect_to_embedded(\n",
    "        environment_variables={\"ENABLE_MODULES\": \"text2vec-ollama,generative-ollama\"},\n",
    "        version=\"1.25.6\"\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d43ac6-7a50-469e-ba87-e5a4398a8994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connecting to Weaviate embedded instance\n",
      "INFO:weaviate-client:Started /opt/app-root/src/.cache/weaviate-embedded: process ID 10008\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":41775},\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"address\":\"10.128.1.110:41776\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"address\":\"10.128.1.110:41775\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"database has been successfully loaded\",\"n\":0,\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"action\":\"raft\",\"index\":23,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:10.128.1.110:34211}]]\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":42,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":42,\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2025-01-21T21:55:22Z\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":14,\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":14,\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"index\":\"Symbols\",\"level\":\"info\",\"msg\":\"restore local index\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2025-01-21T21:55:23Z\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard symbols_lSuTUxNN6vTv in 84.808081ms\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":11000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-01-21T21:55:23Z\",\"took\":34480963}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2025-01-21T21:55:23Z\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "{\"address\":\"10.128.1.110:41775\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/openid-configuration \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/ready \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/.well-known/ready \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Found 1 Weaviate nodes.\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/nodes \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Node(git_hash='\\'\"$GITHASH\"\\'', name='Embedded_at_8079', shards=None, stats=None, status='HEALTHY', version='1.25.6')\n",
      "INFO:root:\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:root:client.get_meta(): {'hostname': 'http://127.0.0.1:8079', 'modules': {'generative-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion', 'name': 'Generative Search - Ollama'}, 'text2vec-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings', 'name': 'Ollama Module'}}, 'version': '1.25.6'}\n"
     ]
    }
   ],
   "source": [
    "client = connect_weaviate_embedded()\n",
    "\n",
    "if client.is_ready():\n",
    "    logging.info('')\n",
    "    logging.info(f'Found {len(client.cluster.nodes())} Weaviate nodes.')\n",
    "    logging.info('')\n",
    "    for node in client.cluster.nodes():\n",
    "        logging.info(node)\n",
    "        logging.info('')\n",
    "    logging.info(f'client.get_meta(): {client.get_meta()}')\n",
    "else:\n",
    "    logging.error(\"Client is not ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ca0be5-5f36-44a3-ba9c-085193782057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/schema \"HTTP/1.1 200 OK\"\n",
      "{\"action\":\"load_all_shards\",\"level\":\"error\",\"msg\":\"failed to load all shards: context canceled\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "INFO:httpx:HTTP Request: DELETE http://localhost:8079/v1/schema/Symbols \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40aff3cc-42f6-44f7-b065-e9d5fa52a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    try:\n",
    "      os.stat(\"data/symbols.json\")\n",
    "      logging.info(\"Symbols already downloaded\")\n",
    "    except:\n",
    "      logging.info(\"Downloading symbols...\")\n",
    "      url = \"https://people.redhat.com/bkozdemb/downloads/symbols.json\"\n",
    "      wget.download(url, \"data/symbols.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dec2267-0263-41d7-a02c-94132a5029a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(client):\n",
    "    # ===== Define the collection =====\n",
    "    symbols = client.collections.create(\n",
    "        name=\"Symbols\",\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n",
    "            api_endpoint=ollama_api_endpoint,\n",
    "            model=ollama_vectorizer_model\n",
    "        ),\n",
    "        generative_config=wvc.config.Configure.Generative.ollama(\n",
    "            api_endpoint=ollama_api_endpoint,\n",
    "            model=ollama_generative_model\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Settings for displaying the import progress\n",
    "    counter = 0\n",
    "    interval = 1000  # Print progress every this many records; should be bigger than the batch_size\n",
    "\n",
    "    logging.info(\"JSON streaming, to avoid running out of memory on large files...\")\n",
    "    with client.batch.fixed_size(batch_size=50) as batch:\n",
    "        with open(\"data/symbols.json\", \"rb\") as f:\n",
    "            objects = ijson.items(f, \"item\")\n",
    "            for obj in objects:\n",
    "                properties = {\n",
    "                    \"Symbol\": obj[\"Symbol\"],\n",
    "                    \"Name\": obj[\"Name\"],\n",
    "                    \"Description\": obj[\"Description\"],\n",
    "                    \"CIK\": obj[\"CIK\"],\n",
    "                    \"Exchange\": obj[\"Exchange\"],\n",
    "                    \"Currency\": obj[\"Currency\"],\n",
    "                    \"Country\": obj[\"Country\"],\n",
    "                    \"Sector\": obj[\"Sector\"], \n",
    "                    \"Industry\": obj[\"Industry\"],\n",
    "                    \"Address\": obj[\"Address\"],\n",
    "                    \"FiscalYearEnd\": obj[\"FiscalYearEnd\"],\n",
    "                    \"LatestQuarter\": obj[\"LatestQuarter\"],\n",
    "                    \"MarketCapitalization\": obj[\"MarketCapitalization\"],\n",
    "                    \"BookValue\": obj[\"BookValue\"],\n",
    "                    \"EBITDA\": obj[\"EBITDA\"],\n",
    "                    \"PERatio\": obj[\"PERatio\"],\n",
    "                    \"PEGRatio\": obj[\"PEGRatio\"],\n",
    "                    \"DividendPerShare\": obj[\"DividendPerShare\"],\n",
    "                    \"DividendYield\": obj[\"DividendYield\"],\n",
    "                    \"EPS\": obj[\"EPS\"],\n",
    "                    \"RevenuePerShareTTM\": obj[\"RevenuePerShareTTM\"],\n",
    "                    \"ProfitMargin\": obj[\"ProfitMargin\"],\n",
    "                    \"OperatingMarginTTM\": obj[\"OperatingMarginTTM\"],\n",
    "                    \"ReturnOnAssetsTTM\": obj[\"ReturnOnAssetsTTM\"],\n",
    "                    \"ReturnOnEquityTTM\": obj[\"ReturnOnEquityTTM\"],\n",
    "                    \"RevenueTTM\": obj[\"RevenueTTM\"],\n",
    "                    \"GrossProfitTTM\": obj[\"GrossProfitTTM\"],\n",
    "                    \"DilutedEPSTTM\": obj[\"DilutedEPSTTM\"],\n",
    "                    \"QuarterlyEarningsGrowthYOY\": obj[\"QuarterlyEarningsGrowthYOY\"],\n",
    "                    \"QuarterlyRevenueGrowthYOY\": obj[\"QuarterlyRevenueGrowthYOY\"],\n",
    "                    \"AnalystTargetPrice\": obj[\"AnalystTargetPrice\"],\n",
    "                    \"AnalystRatingStrongBuy\": obj[\"AnalystRatingStrongBuy\"],\n",
    "                    \"AnalystRatingBuy\": obj[\"AnalystRatingBuy\"],\n",
    "                    \"AnalystRatingHold\": obj[\"AnalystRatingHold\"],\n",
    "                    \"AnalystRatingSell\": obj[\"AnalystRatingSell\"],\n",
    "                    \"AnalystRatingStrongSell\": obj[\"AnalystRatingStrongSell\"],\n",
    "                    \"TrailingPE\": obj[\"TrailingPE\"],\n",
    "                    \"ForwardPE\": obj[\"ForwardPE\"],\n",
    "                    \"PriceToSalesRatioTTM\": obj[\"PriceToSalesRatioTTM\"],\n",
    "                    \"PriceToBookRatio\": obj[\"PriceToBookRatio\"],\n",
    "                    \"EVToRevenue\": obj[\"EVToRevenue\"],\n",
    "                    \"EVToEBITDA\": obj[\"EVToEBITDA\"],\n",
    "                    \"Beta\": obj[\"Beta\"],\n",
    "                    \"fiftytwoWeekHigh\": obj[\"52WeekHigh\"],\n",
    "                    \"fiftytwoWeekLow\": obj[\"52WeekLow\"],\n",
    "                    \"fiftyDayMovingAverage\": obj[\"50DayMovingAverage\"],\n",
    "                    \"twohundredDayMovingAverage\": obj[\"200DayMovingAverage\"],\n",
    "                    \"SharesOutstanding\": obj[\"SharesOutstanding\"],\n",
    "                    \"DividendDate\": obj[\"DividendDate\"],\n",
    "                    \"ExDividendDate\": obj[\"ExDividendDate\"]\n",
    "                }\n",
    "                batch.add_object(\n",
    "                    collection=\"Symbols\",\n",
    "                    properties=properties,\n",
    "                    # If you Bring Your Own Vectors, add the `vector` parameter here\n",
    "                    # vector=obj.vector[\"default\"]\n",
    "                )\n",
    "\n",
    "                # Calculate and display progress\n",
    "                counter += 1\n",
    "                if counter % interval == 0:\n",
    "                    logging.info(f\"Imported {counter} of 7116 stock symbols.\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Finished importing {counter} symbols.\")\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf56dae6-e396-4ed0-8e63-61eaaf838113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query='computers', limit=2) -> dict:\n",
    "    print(f'\\nSemantic Search, query = {query}.')\n",
    "    print(f'limit = {limit}')\n",
    "    response = symbols.query.near_text(\n",
    "        query=query,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "    return_list = []\n",
    "    for i in range(limit):\n",
    "        return_list.append(response.objects[i].properties['name'])\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61f720f-5656-450f-8249-063e3d7e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_search(query='computers', task=None, limit=2) -> str:\n",
    "    print(f'\\nPerforming generative search, query = {query}, limit = {limit}.')\n",
    "    print(f'Prompt: {task}')\n",
    "    print(f'limit = {limit}')\n",
    "    response = symbols.generate.near_text(\n",
    "        query=query,\n",
    "        limit=limit,\n",
    "        grouped_task=task\n",
    "    )\n",
    "    return response.generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44163989-9e3a-4b93-be3a-1a37730230a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Symbols already downloaded\n",
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /opt/app-root/src/.local/share/weaviate/symbols/85SAhcdenrBD/proplengths does not exist, creating new tracker\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2025-01-21T21:55:24Z\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard symbols_85SAhcdenrBD in 2.488107ms\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-01-21T21:55:24Z\",\"took\":49810}\n",
      "INFO:httpx:HTTP Request: POST http://localhost:8079/v1/schema \"HTTP/1.1 200 OK\"\n",
      "INFO:root:JSON streaming, to avoid running out of memory on large files...\n",
      "INFO:httpx:HTTP Request: GET http://localhost:8079/v1/schema \"HTTP/1.1 200 OK\"\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:ca8d0aa4-6c1c-4a4f-9ad2-34d6cd1b1e56 Type:INIT Version:1.25.6 NumObjects:0 OS:linux Arch:amd64 UsedModules:[generative-ollama text2vec-ollama]}\",\"time\":\"2025-01-21T21:55:24Z\"}\n",
      "INFO:root:Imported 1000 of 7116 stock symbols.\n",
      "INFO:root:Imported 2000 of 7116 stock symbols.\n",
      "INFO:root:Imported 3000 of 7116 stock symbols.\n",
      "INFO:root:Imported 4000 of 7116 stock symbols.\n",
      "INFO:root:Imported 5000 of 7116 stock symbols.\n",
      "INFO:root:Imported 6000 of 7116 stock symbols.\n",
      "INFO:root:Imported 7000 of 7116 stock symbols.\n",
      "INFO:root:Finished importing 7116 symbols.\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "/opt/app-root/lib64/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
      "  from websockets.server import WebSocketServerProtocol\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:8081/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://localhost:8081/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://adb32ca4e2d87ef8b8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://adb32ca4e2d87ef8b8.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://adb32ca4e2d87ef8b8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Search, query = Commodities.\n",
      "limit = 2\n",
      "\n",
      "Performing generative search, query = Commodities, limit = 2.\n",
      "Prompt: Summarize the information from a financial investment perspective.\n",
      "limit = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Shutting down... \",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Stopped serving weaviate at http://127.0.0.1:8079\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry terminated\",\"payload\":\"\\u0026{MachineID:ca8d0aa4-6c1c-4a4f-9ad2-34d6cd1b1e56 Type:TERMINATE Version:1.25.6 NumObjects:7116 OS:linux Arch:amd64 UsedModules:[generative-ollama text2vec-ollama]}\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing raft FSM store ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"shutting down raft sub-system ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"transferring leadership to another server\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing raft-net ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing log store ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing data store ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing loaded database ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing raft-rpc client ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n",
      "{\"level\":\"info\",\"msg\":\"closing raft-rpc server ...\",\"time\":\"2025-01-21T21:56:51Z\"}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    download_data()\n",
    "    symbols = ingest_data(client)\n",
    "    #\n",
    "    # Build the Gradio user interface.\n",
    "    #\n",
    "    with gr.Blocks(title='Summarizing Financial Data using RAG') as demo:\n",
    "            gr.Markdown(\"\"\"# Summarizing Financial Data using Retrieval Augmented Generation (RAG).\"\"\")\n",
    "            semantic_examples = [\n",
    "                [\"Computers\"],\n",
    "                [\"Computer Software\"],\n",
    "                [\"Pharmaceuticals\"],\n",
    "                [\"Consumer Products\"],\n",
    "                [\"Commodities\"],\n",
    "                [\"Retail\"],\n",
    "                [\"Manufacturing\"],\n",
    "                [\"Energy\"],\n",
    "                [\"National Defense\"],\n",
    "                [\"Auto Makers\"]\n",
    "            ]\n",
    "            gr.Markdown(\"\"\"### Begin with a search.\"\"\")\n",
    "            semantic_input_text = gr.Textbox(label=\"Enter a search concept or choose an example below:\", value=semantic_examples[0][0])\n",
    "            gr.Examples(semantic_examples,\n",
    "                fn=semantic_search,\n",
    "                inputs=semantic_input_text, label=\"Example search concepts:\"\n",
    "                )\n",
    "            limit_slider = gr.Slider(label=\"Adjust the query return limit. (Optional)\",value=2, minimum=1, maximum=5, step=1)\n",
    "            vdb_button = gr.Button(value=\"Search the financial vector database.\")\n",
    "            vdb_button.click(fn=semantic_search, inputs=[semantic_input_text, limit_slider], outputs=gr.Textbox(label=\"Search Results (Filters = Name)\"))\n",
    "            \n",
    "            prompt_examples = [\n",
    "                [\"Generate a paragraph that summarizes the given information from a financial perspective for the fiscal year end of December 2024.\"],\n",
    "                [\"Summarize the information from a financial investment perspective.\"],\n",
    "                [\"Summarize the potential financial investment risks and rewards.\"]\n",
    "            ]\n",
    "\n",
    "            gr.Markdown(\"\"\"### Summarize\"\"\")\n",
    "            generative_search_prompt_text = gr.Textbox(label=\"Enter a summarization task or choose an example below.\", value=prompt_examples[0][0])\n",
    "            gr.Examples(prompt_examples,\n",
    "                fn=generative_search,\n",
    "                inputs=[generative_search_prompt_text]\n",
    "            )\n",
    "            button = gr.Button(value=\"Generate the summary.\")\n",
    "            button.click(fn=generative_search,\n",
    "            inputs=[semantic_input_text, generative_search_prompt_text, limit_slider],\n",
    "            outputs=gr.Textbox(label=\"Summary\"))\n",
    "            \n",
    "    demo.queue(max_size=10)\n",
    "    demo.launch(server_name='0.0.0.0', server_port=8081, share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
