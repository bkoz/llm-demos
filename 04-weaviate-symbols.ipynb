{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdce3d0-3e19-4018-8e20-35d45f34975e",
   "metadata": {},
   "source": [
    "### FinRAG Demo with Gradio, Weaviate and Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376adfc-a3e3-4926-a663-defee5e8c5ec",
   "metadata": {},
   "source": [
    "#### This notebook expects the Ollama server to be backed by GPU with 16GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742381c-7de1-4e78-a05b-0933fbf945c7",
   "metadata": {},
   "source": [
    "#### This is a lite version that uses Weaviate's embedded instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e061a-3c67-4719-a9ec-88dcd3f3d5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pip gradio weaviate_client wget ijson -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2d3fd-781a-472b-b29a-c99bc3df5b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from huggingface_hub import InferenceClient\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import ijson\n",
    "import weaviate\n",
    "\n",
    "ollama_api_endpoint = os.getenv(\"OLLAMA_HOST\", \"http://ollama.ollama\")\n",
    "ollama_vectorizer_model = model = \"all-minilm\"\n",
    "ollama_generative_model=\"granite3-dense:8b\"\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.info(f'OLLAMA_API_ENDPOINT = {ollama_api_endpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2814fc4-5762-4665-9343-a5f4ff637e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def connect_weaviate_embedded():\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    logging.info('Connecting to Weaviate embedded instance')\n",
    "    client = weaviate.connect_to_embedded(\n",
    "        environment_variables={\"ENABLE_MODULES\": \"text2vec-ollama,generative-ollama\"},\n",
    "        version=\"1.25.6\"\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d43ac6-7a50-469e-ba87-e5a4398a8994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = connect_weaviate_embedded()\n",
    "\n",
    "if client.is_ready():\n",
    "    logging.info('')\n",
    "    logging.info(f'Found {len(client.cluster.nodes())} Weaviate nodes.')\n",
    "    logging.info('')\n",
    "    for node in client.cluster.nodes():\n",
    "        logging.info(node)\n",
    "        logging.info('')\n",
    "    logging.info(f'client.get_meta(): {client.get_meta()}')\n",
    "else:\n",
    "    logging.error(\"Client is not ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca0be5-5f36-44a3-ba9c-085193782057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aff3cc-42f6-44f7-b065-e9d5fa52a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    try:\n",
    "      os.stat(\"data/symbols.json\")\n",
    "      logging.info(\"Symbols already downloaded\")\n",
    "    except:\n",
    "      logging.info(\"Downloading symbols...\")\n",
    "      url = \"https://people.redhat.com/bkozdemb/downloads/symbols.json\"\n",
    "      wget.download(url, \"data/symbols.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec2267-0263-41d7-a02c-94132a5029a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(client):\n",
    "\n",
    "    # ===== Define the collection =====\n",
    "    symbols = client.collections.create(\n",
    "        name=\"Symbols\",\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_ollama(\n",
    "            api_endpoint=ollama_api_endpoint,\n",
    "            model=ollama_vectorizer_model\n",
    "        ),\n",
    "        generative_config=wvc.config.Configure.Generative.ollama(\n",
    "            api_endpoint=ollama_api_endpoint,\n",
    "            model=ollama_generative_model\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Settings for displaying the import progress\n",
    "    counter = 0\n",
    "    interval = 1000  # Print progress every this many records; should be bigger than the batch_size\n",
    "\n",
    "    logging.info(\"JSON streaming, to avoid running out of memory on large files...\")\n",
    "    with client.batch.fixed_size(batch_size=50) as batch:\n",
    "        with open(\"data/symbols.json\", \"rb\") as f:\n",
    "            objects = ijson.items(f, \"item\")\n",
    "            for obj in objects:\n",
    "                properties = {\n",
    "                    \"Symbol\": obj[\"Symbol\"],\n",
    "                    \"Name\": obj[\"Name\"],\n",
    "                    \"Description\": obj[\"Description\"],\n",
    "                    \"CIK\": obj[\"CIK\"],\n",
    "                    \"Exchange\": obj[\"Exchange\"],\n",
    "                    \"Currency\": obj[\"Currency\"],\n",
    "                    \"Country\": obj[\"Country\"],\n",
    "                    \"Sector\": obj[\"Sector\"], \n",
    "                    \"Industry\": obj[\"Industry\"],\n",
    "                    \"Address\": obj[\"Address\"],\n",
    "                    \"FiscalYearEnd\": obj[\"FiscalYearEnd\"],\n",
    "                    \"LatestQuarter\": obj[\"LatestQuarter\"],\n",
    "                    \"MarketCapitalization\": obj[\"MarketCapitalization\"],\n",
    "                    \"BookValue\": obj[\"BookValue\"],\n",
    "                    \"EBITDA\": obj[\"EBITDA\"],\n",
    "                    \"PERatio\": obj[\"PERatio\"],\n",
    "                    \"PEGRatio\": obj[\"PEGRatio\"],\n",
    "                    \"DividendPerShare\": obj[\"DividendPerShare\"],\n",
    "                    \"DividendYield\": obj[\"DividendYield\"],\n",
    "                    \"EPS\": obj[\"EPS\"],\n",
    "                    \"RevenuePerShareTTM\": obj[\"RevenuePerShareTTM\"],\n",
    "                    \"ProfitMargin\": obj[\"ProfitMargin\"],\n",
    "                    \"OperatingMarginTTM\": obj[\"OperatingMarginTTM\"],\n",
    "                    \"ReturnOnAssetsTTM\": obj[\"ReturnOnAssetsTTM\"],\n",
    "                    \"ReturnOnEquityTTM\": obj[\"ReturnOnEquityTTM\"],\n",
    "                    \"RevenueTTM\": obj[\"RevenueTTM\"],\n",
    "                    \"GrossProfitTTM\": obj[\"GrossProfitTTM\"],\n",
    "                    \"DilutedEPSTTM\": obj[\"DilutedEPSTTM\"],\n",
    "                    \"QuarterlyEarningsGrowthYOY\": obj[\"QuarterlyEarningsGrowthYOY\"],\n",
    "                    \"QuarterlyRevenueGrowthYOY\": obj[\"QuarterlyRevenueGrowthYOY\"],\n",
    "                    \"AnalystTargetPrice\": obj[\"AnalystTargetPrice\"],\n",
    "                    \"AnalystRatingStrongBuy\": obj[\"AnalystRatingStrongBuy\"],\n",
    "                    \"AnalystRatingBuy\": obj[\"AnalystRatingBuy\"],\n",
    "                    \"AnalystRatingHold\": obj[\"AnalystRatingHold\"],\n",
    "                    \"AnalystRatingSell\": obj[\"AnalystRatingSell\"],\n",
    "                    \"AnalystRatingStrongSell\": obj[\"AnalystRatingStrongSell\"],\n",
    "                    \"TrailingPE\": obj[\"TrailingPE\"],\n",
    "                    \"ForwardPE\": obj[\"ForwardPE\"],\n",
    "                    \"PriceToSalesRatioTTM\": obj[\"PriceToSalesRatioTTM\"],\n",
    "                    \"PriceToBookRatio\": obj[\"PriceToBookRatio\"],\n",
    "                    \"EVToRevenue\": obj[\"EVToRevenue\"],\n",
    "                    \"EVToEBITDA\": obj[\"EVToEBITDA\"],\n",
    "                    \"Beta\": obj[\"Beta\"],\n",
    "                    \"fiftytwoWeekHigh\": obj[\"52WeekHigh\"],\n",
    "                    \"fiftytwoWeekLow\": obj[\"52WeekLow\"],\n",
    "                    \"fiftyDayMovingAverage\": obj[\"50DayMovingAverage\"],\n",
    "                    \"twohundredDayMovingAverage\": obj[\"200DayMovingAverage\"],\n",
    "                    \"SharesOutstanding\": obj[\"SharesOutstanding\"],\n",
    "                    \"DividendDate\": obj[\"DividendDate\"],\n",
    "                    \"ExDividendDate\": obj[\"ExDividendDate\"]\n",
    "                }\n",
    "                batch.add_object(\n",
    "                    collection=\"Symbols\",\n",
    "                    properties=properties,\n",
    "                    # If you Bring Your Own Vectors, add the `vector` parameter here\n",
    "                    # vector=obj.vector[\"default\"]\n",
    "                )\n",
    "\n",
    "                # Calculate and display progress\n",
    "                counter += 1\n",
    "                if counter % interval == 0:\n",
    "                    logging.info(f\"Imported {counter} of 7116 stock symbols.\")\n",
    "\n",
    "\n",
    "    logging.info(f\"Finished importing {counter} symbols.\")\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56dae6-e396-4ed0-8e63-61eaaf838113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query='computers', limit=2) -> dict:\n",
    "    print(f'\\nSemantic Search, query = {query}.')\n",
    "    print(f'limit = {limit}')\n",
    "    response = symbols.query.near_text(\n",
    "        query=query,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "    return_list = []\n",
    "    for i in range(limit):\n",
    "        return_list.append(response.objects[i].properties['name'])\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f720f-5656-450f-8249-063e3d7e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_search(query='computers', task=None, limit=2) -> str:\n",
    "    print(f'\\nPerforming generative search, query = {query}, limit = {limit}.')\n",
    "    print(f'Prompt: {task}')\n",
    "    print(f'limit = {limit}')\n",
    "    response = symbols.generate.near_text(\n",
    "        query=query,\n",
    "        limit=limit,\n",
    "        grouped_task=task\n",
    "    )\n",
    "    return response.generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44163989-9e3a-4b93-be3a-1a37730230a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    download_data()\n",
    "    symbols = ingest_data(client)\n",
    "    #\n",
    "    # Build the Gradio user interface.\n",
    "    #\n",
    "    with gr.Blocks(title='Summarizing Financial Data using RAG') as demo:\n",
    "            gr.Markdown(\"\"\"# Summarizing Financial Data using Retrieval Augmented Generation (RAG).\"\"\")\n",
    "            semantic_examples = [\n",
    "                [\"Computers\"],\n",
    "                [\"Computer Software\"],\n",
    "                [\"Pharmaceuticals\"],\n",
    "                [\"Consumer Products\"],\n",
    "                [\"Commodities\"],\n",
    "                [\"Retail\"],\n",
    "                [\"Manufacturing\"],\n",
    "                [\"Energy\"],\n",
    "                [\"National Defense\"],\n",
    "                [\"Auto Makers\"]\n",
    "            ]\n",
    "            gr.Markdown(\"\"\"### Begin with a search.\"\"\")\n",
    "            semantic_input_text = gr.Textbox(label=\"Enter a search concept or choose an example below:\", value=semantic_examples[0][0])\n",
    "            gr.Examples(semantic_examples,\n",
    "                fn=semantic_search,\n",
    "                inputs=semantic_input_text, label=\"Example search concepts:\"\n",
    "                )\n",
    "            limit_slider = gr.Slider(label=\"Adjust the query return limit. (Optional)\",value=2, minimum=1, maximum=5, step=1)\n",
    "            vdb_button = gr.Button(value=\"Search the financial vector database.\")\n",
    "            vdb_button.click(fn=semantic_search, inputs=[semantic_input_text, limit_slider], outputs=gr.Textbox(label=\"Search Results (Filters = Name)\"))\n",
    "            \n",
    "            prompt_examples = [\n",
    "                [\"Generate a paragraph that summarizes the given information from a financial perspective for the fiscal year end of December 2024.\"],\n",
    "                [\"Summarize the information from a financial investment perspective.\"],\n",
    "                [\"Summarize the potential financial investment risks and rewards.\"]\n",
    "            ]\n",
    "\n",
    "            gr.Markdown(\"\"\"### Summarize\"\"\")\n",
    "            generative_search_prompt_text = gr.Textbox(label=\"Enter a summarization task or choose an example below.\", value=prompt_examples[0][0])\n",
    "            gr.Examples(prompt_examples,\n",
    "                fn=generative_search,\n",
    "                inputs=[generative_search_prompt_text]\n",
    "            )\n",
    "            button = gr.Button(value=\"Generate the summary.\")\n",
    "            button.click(fn=generative_search,\n",
    "            inputs=[semantic_input_text, generative_search_prompt_text, limit_slider],\n",
    "            outputs=gr.Textbox(label=\"Summary\"))\n",
    "            \n",
    "    demo.queue(max_size=10)\n",
    "    demo.launch(server_name='0.0.0.0', server_port=8081, share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
